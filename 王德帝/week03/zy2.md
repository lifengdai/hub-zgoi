# 文本分类方法对比

本文档对比了几种常见的文本分类方法，包括 **正则表达式、TF-IDF、BERT、大语言模型 (LLM)**，总结了它们的原理、优点和缺点。

---

## 1. 正则表达式（Regex）

### 📌 原理
- 使用预定义的模式匹配规则，从文本中提取关键字或结构特征。
- 依赖人工编写的规则，而不是从数据中自动学习。

### ✅ 优点
- 简单直观，适合规则明确的文本（如日志、固定格式的票据）。
- 不需要训练数据，直接上线。
- 计算开销小，速度快。

### ❌ 缺点
- 泛化能力差，无法处理复杂语义。
- 需要人工维护规则，成本高。
- 难以应对词汇多样性和歧义。

---

## 2. TF-IDF（词频-逆文档频率）

### 📌 原理
- 将文本表示为 **词袋模型 (Bag-of-Words)**，统计每个词的重要性。
- 高频但在所有文档中普遍出现的词（如“的”、“是”）权重降低，区分性强的词权重提高。

### ✅ 优点
- 实现简单，容易理解。
- 适合传统机器学习模型（如 SVM、逻辑回归）。
- 在小规模数据集上表现良好。

### ❌ 缺点
- 丢失词序信息，无法表达上下文。
- 向量维度高且稀疏。
- 无法捕捉语义相似性（“汽车”和“轿车”完全不同）。

---

## 3. BERT（Bidirectional Encoder Representations from Transformers）

### 📌 原理
- 基于 **Transformer** 的双向语言模型，通过掩码预测和下一句预测进行预训练。
- 可以得到上下文相关的词向量表示。
- 常用于文本分类的下游任务（在预训练模型上 fine-tune）。

### ✅ 优点
- 能捕捉上下文语义，比传统方法更强大。
- 在大多数 NLP 任务中表现出色。
- 预训练模型开源丰富，直接迁移使用。

### ❌ 缺点
- 计算成本高，推理速度慢。
- 模型较大，部署资源消耗大。
- 对小数据集可能过拟合，需要正则化或数据增强。

---

## 4. 大语言模型（LLM，如 GPT、LLaMA、ChatGLM）

### 📌 原理
- 超大规模 Transformer 模型，基于海量语料训练。
- 具备强大的 **上下文理解能力** 和 **零样本/少样本学习能力**。
- 可以通过 **提示词 (prompting)** 直接完成分类任务。

### ✅ 优点
- 不需要专门训练，直接通过 prompt 进行分类。
- 语义理解能力极强，能处理复杂文本。
- 适应性强，可快速迁移到新任务。

### ❌ 缺点
- 计算和存储成本极高（训练和部署都昂贵）。
- 可能产生幻觉（给出看似合理但错误的答案）。
- 依赖外部大模型时存在隐私和可控性问题。

---

## 📊 方法对比总结

| 方法            | 是否需要训练 | 语义理解能力 | 可扩展性 | 适合场景 |
|-----------------|--------------|---------------|-----------|-----------|
| 正则表达式      | ❌ 不需要    | 🚫 极弱       | 🚫 差     | 规则固定任务（如日志分类） |
| TF-IDF          | ✅ 需要      | ⚠️ 较弱       | ✅ 中等   | 中小规模文本分类 |
| BERT            | ✅ 需要微调  | ✅ 强         | ✅ 强     | 通用 NLP 分类 |
| 大语言模型 LLM  | ❌ 零样本可用 | 🚀 极强       | ⚠️ 成本高 | 高级文本理解、复杂分类 |

---
